{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Task 1\n",
    "\n",
    "# Import libraries\n",
    "\n",
    "import os\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Set up BigQuery client\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\service_account_key.json'  \n",
    "client = bigquery.Client()\n",
    "\n",
    "# Directory where data files are stored\n",
    "data_dir = r'C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attach GBQ\n",
    "\n",
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Set the environment variable for the service account key\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\service_account_key.json'\n",
    "\n",
    "# Initialize the BigQuery client\n",
    "client = bigquery.Client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>register_no</th>\n",
       "      <th>emp_no</th>\n",
       "      <th>trans_no</th>\n",
       "      <th>upc</th>\n",
       "      <th>description</th>\n",
       "      <th>trans_type</th>\n",
       "      <th>trans_subtype</th>\n",
       "      <th>trans_status</th>\n",
       "      <th>department</th>\n",
       "      <th>...</th>\n",
       "      <th>batchHeaderID</th>\n",
       "      <th>local</th>\n",
       "      <th>organic</th>\n",
       "      <th>display</th>\n",
       "      <th>receipt</th>\n",
       "      <th>card_no</th>\n",
       "      <th>store</th>\n",
       "      <th>branch</th>\n",
       "      <th>match_id</th>\n",
       "      <th>trans_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-01 07:13:09</td>\n",
       "      <td>51</td>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Change</td>\n",
       "      <td>T</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20074</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-01 08:28:43</td>\n",
       "      <td>51</td>\n",
       "      <td>94</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>T</td>\n",
       "      <td>CC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-01 08:44:56</td>\n",
       "      <td>51</td>\n",
       "      <td>94</td>\n",
       "      <td>47</td>\n",
       "      <td>TAX</td>\n",
       "      <td>Tax</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10499</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-01 07:20:34</td>\n",
       "      <td>51</td>\n",
       "      <td>94</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Change</td>\n",
       "      <td>T</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12539</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-01 08:57:38</td>\n",
       "      <td>51</td>\n",
       "      <td>94</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>T</td>\n",
       "      <td>CC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16360</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  register_no  emp_no  trans_no  upc  description  \\\n",
       "0  2016-09-01 07:13:09           51      94         6    0       Change   \n",
       "1  2016-09-01 08:28:43           51      94        37    0  Credit Card   \n",
       "2  2016-09-01 08:44:56           51      94        47  TAX          Tax   \n",
       "3  2016-09-01 07:20:34           51      94        10    0       Change   \n",
       "4  2016-09-01 08:57:38           51      94        50    0  Credit Card   \n",
       "\n",
       "  trans_type trans_subtype trans_status  department  ...  batchHeaderID  \\\n",
       "0          T            CA          NaN           0  ...            NaN   \n",
       "1          T            CC          NaN           0  ...            NaN   \n",
       "2          A           NaN          NaN           0  ...            NaN   \n",
       "3          T            CA          NaN           0  ...            NaN   \n",
       "4          T            CC          NaN           0  ...            NaN   \n",
       "\n",
       "   local  organic  display  receipt  card_no  store  branch  match_id  \\\n",
       "0    0.0      NaN      NaN      0.0    20074      1       3       0.0   \n",
       "1    0.0      NaN      NaN      0.0        3      1       3       0.0   \n",
       "2    0.0      NaN      NaN      0.0    10499      1       3       0.0   \n",
       "3    0.0      NaN      NaN      0.0    12539      1       3       0.0   \n",
       "4    0.0      NaN      NaN      0.0    16360      1       3       0.0   \n",
       "\n",
       "   trans_id  \n",
       "0         7  \n",
       "1         7  \n",
       "2        12  \n",
       "3         9  \n",
       "4        11  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Use raw string for file path\n",
    "file_path = r'C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201609_clean.csv'\n",
    "\n",
    "# Read the CSV file, correcting escape character issues\n",
    "df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N', r'\\\\N'])\n",
    "\n",
    "# Display the first few rows of the dataframe to inspect it\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201001_201003_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:04, 184.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2998330 rows to wedge_project_ochoa.transArchive_201001_201003_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201004_201006_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:25, 205.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3185807 rows to wedge_project_ochoa.transArchive_201004_201006_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201007_201009_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:26, 206.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2992585 rows to wedge_project_ochoa.transArchive_201007_201009_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201010_201012_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\2121878544.py:31: DtypeWarning: Columns (43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:28, 208.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2957586 rows to wedge_project_ochoa.transArchive_201010_201012_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201101_201103_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:43, 223.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2920826 rows to wedge_project_ochoa.transArchive_201101_201103_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201104_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:34, 94.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 1066334 rows to wedge_project_ochoa.transArchive_201104_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201105_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:23, 83.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 1068515 rows to wedge_project_ochoa.transArchive_201105_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201106_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:33, 93.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 992906 rows to wedge_project_ochoa.transArchive_201106_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201107_201109_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:34, 214.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3011935 rows to wedge_project_ochoa.transArchive_201107_201109_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201110_201112_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:34, 214.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3121117 rows to wedge_project_ochoa.transArchive_201110_201112_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201201_201203_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:55, 235.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2989644 rows to wedge_project_ochoa.transArchive_201201_201203_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201201_201203_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:20, 20.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 245772 rows to wedge_project_ochoa.transArchive_201201_201203_inactive_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201204_201206_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\2121878544.py:31: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:22, 202.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3083546 rows to wedge_project_ochoa.transArchive_201204_201206_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201204_201206_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:26, 26.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 237990 rows to wedge_project_ochoa.transArchive_201204_201206_inactive_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201207_201209_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\2121878544.py:31: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:12, 192.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2925608 rows to wedge_project_ochoa.transArchive_201207_201209_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201207_201209_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\2121878544.py:31: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [00:19, 19.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 190877 rows to wedge_project_ochoa.transArchive_201207_201209_inactive_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201210_201212_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\2121878544.py:31: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:38, 218.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2893637 rows to wedge_project_ochoa.transArchive_201210_201212_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201210_201212_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\2121878544.py:31: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [00:17, 17.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 162988 rows to wedge_project_ochoa.transArchive_201210_201212_inactive_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201301_201303_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\2121878544.py:31: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:20, 200.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2903987 rows to wedge_project_ochoa.transArchive_201301_201303_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201301_201303_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\2121878544.py:31: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [00:14, 14.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 148623 rows to wedge_project_ochoa.transArchive_201301_201303_inactive_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201304_201306_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\2121878544.py:31: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:52, 232.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3025434 rows to wedge_project_ochoa.transArchive_201304_201306_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201304_201306_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\2121878544.py:31: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [00:38, 38.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 137628 rows to wedge_project_ochoa.transArchive_201304_201306_inactive_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201307_201309_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\2121878544.py:31: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [04:10, 250.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2997135 rows to wedge_project_ochoa.transArchive_201307_201309_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201307_201309_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:13, 13.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 104468 rows to wedge_project_ochoa.transArchive_201307_201309_inactive_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201310_201312_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\2121878544.py:31: DtypeWarning: Columns (33,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:38, 218.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2922057 rows to wedge_project_ochoa.transArchive_201310_201312_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201310_201312_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:12, 12.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 79156 rows to wedge_project_ochoa.transArchive_201310_201312_inactive_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201401_201403_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\2121878544.py:31: DtypeWarning: Columns (33,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:19, 199.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2916194 rows to wedge_project_ochoa.transArchive_201401_201403_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201401_201403_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\2121878544.py:31: DtypeWarning: Columns (43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [00:07,  7.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 52614 rows to wedge_project_ochoa.transArchive_201401_201403_inactive_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201404_201406_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_14096\\2121878544.py:31: DtypeWarning: Columns (33,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
      "1it [03:48, 228.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3154267 rows to wedge_project_ochoa.transArchive_201404_201406_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201404_201406_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:08,  8.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 49069 rows to wedge_project_ochoa.transArchive_201404_201406_inactive_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201407_201409_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:32, 212.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3030409 rows to wedge_project_ochoa.transArchive_201407_201409_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201407_201409_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:09,  9.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 28323 rows to wedge_project_ochoa.transArchive_201407_201409_inactive_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201410_201412_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:44, 224.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2931416 rows to wedge_project_ochoa.transArchive_201410_201412_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201410_201412_inactive_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 7964 rows to wedge_project_ochoa.transArchive_201410_201412_inactive_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201501_201503_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:44, 224.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3041129 rows to wedge_project_ochoa.transArchive_201501_201503_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201504_201506_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:58, 238.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3274964 rows to wedge_project_ochoa.transArchive_201504_201506_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201507_201509_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [05:57, 357.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 3124699 rows to wedge_project_ochoa.transArchive_201507_201509_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201510_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:29, 89.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 1006055 rows to wedge_project_ochoa.transArchive_201510_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201511_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:19, 79.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 993744 rows to wedge_project_ochoa.transArchive_201511_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201512_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:12, 72.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 960017 rows to wedge_project_ochoa.transArchive_201512_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201601_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:19, 79.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 979408 rows to wedge_project_ochoa.transArchive_201601_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201602_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:23, 83.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 874853 rows to wedge_project_ochoa.transArchive_201602_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201603_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:14, 74.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 964635 rows to wedge_project_ochoa.transArchive_201603_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201604_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:14, 74.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 930359 rows to wedge_project_ochoa.transArchive_201604_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201605_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:13, 73.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 938769 rows to wedge_project_ochoa.transArchive_201605_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201606_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:17, 77.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 862329 rows to wedge_project_ochoa.transArchive_201606_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201607_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:07, 67.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 872161 rows to wedge_project_ochoa.transArchive_201607_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201608_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:18, 78.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 858168 rows to wedge_project_ochoa.transArchive_201608_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201609_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:23, 83.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 861248 rows to wedge_project_ochoa.transArchive_201609_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201610_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:27, 87.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 905092 rows to wedge_project_ochoa.transArchive_201610_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201611_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:18, 78.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 925314 rows to wedge_project_ochoa.transArchive_201611_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201612_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:15, 75.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 915707 rows to wedge_project_ochoa.transArchive_201612_clean\n",
      "Processing file: C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data\\transArchive_201701_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:16, 76.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 936741 rows to wedge_project_ochoa.transArchive_201701_clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "\n",
    "# Directory where the CSV files are stored\n",
    "data_dir = r'C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\data'\n",
    "\n",
    "# Function to upload a DataFrame to BigQuery\n",
    "def upload_to_bigquery(df, table_name):\n",
    "\n",
    "    table_id = f\"wedge_project_ochoa.{table_name}\"     \n",
    "    # Upload the DataFrame to BigQuery using pandas_gbq with CSV format\n",
    "    pandas_gbq.to_gbq(\n",
    "        df, \n",
    "        table_id, \n",
    "        project_id=\"umt-msba\", \n",
    "        if_exists=\"replace\", \n",
    "        api_method=\"load_csv\" \n",
    "    )\n",
    "\n",
    "    print(f\"Uploaded {len(df)} rows to {table_id}\")\n",
    "\n",
    "# Loop through all CSV files in the directory and upload each to BigQuery\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if file_name.endswith('.csv'): \n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "\n",
    "        # Read the CSV into a DataFrame\n",
    "        df = pd.read_csv(file_path, delimiter=',', na_values=['NULL', '\\\\N'])\n",
    "\n",
    "        # Extract the table name from the file name .\n",
    "\n",
    "        \n",
    "        table_name = file_name.split('.')[0]\n",
    "\n",
    "        # Upload the DataFrame to BigQuery\n",
    "        upload_to_bigquery(df, table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "404 Not found: Table umt-msba:wedge_project_ochoa.transactions was not found in location US; reason: notFound, message: Not found: Table umt-msba:wedge_project_ochoa.transactions was not found in location US\n\nLocation: US\nJob ID: 4955f81d-b682-4711-a544-aba1f743db48\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Main workflow\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 60\u001b[0m     owners \u001b[38;5;241m=\u001b[39m \u001b[43mget_owner_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     61\u001b[0m     sampled_owners \u001b[38;5;241m=\u001b[39m sample_owners(owners)  \n\u001b[0;32m     62\u001b[0m     sampled_records \u001b[38;5;241m=\u001b[39m extract_records_for_sampled_owners(sampled_owners) \n",
      "Cell \u001b[1;32mIn[28], line 21\u001b[0m, in \u001b[0;36mget_owner_records\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_owner_records\u001b[39m():\n\u001b[0;32m     16\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m    SELECT * \u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124m    FROM `umt-msba.wedge_project_ochoa.transactions`\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124m    WHERE card_no != 3\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 21\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\cloud\\bigquery\\job\\query.py:2052\u001b[0m, in \u001b[0;36mto_dataframe\u001b[1;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[0;32m   1828\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1829\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1849\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[0;32m   1850\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[0;32m   1852\u001b[0m \n\u001b[0;32m   1853\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;124;03m        bqstorage_client (Optional[google.cloud.bigquery_storage_v1.BigQueryReadClient]):\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m \u001b[38;5;124;03m            A BigQuery Storage API client. If supplied, use the faster\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m \u001b[38;5;124;03m            BigQuery Storage API to fetch rows from BigQuery. This\u001b[39;00m\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;124;03m            API is a billable API.\u001b[39;00m\n\u001b[0;32m   1858\u001b[0m \n\u001b[0;32m   1859\u001b[0m \u001b[38;5;124;03m            This method requires the ``fastavro`` and\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[38;5;124;03m            ``google-cloud-bigquery-storage`` libraries.\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \n\u001b[0;32m   1862\u001b[0m \u001b[38;5;124;03m            Reading from a specific partition or snapshot is not\u001b[39;00m\n\u001b[0;32m   1863\u001b[0m \u001b[38;5;124;03m            currently supported by this method.\u001b[39;00m\n\u001b[0;32m   1864\u001b[0m \n\u001b[0;32m   1865\u001b[0m \u001b[38;5;124;03m        dtypes (Optional[Map[str, Union[str, pandas.Series.dtype]]]):\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;124;03m            A dictionary of column names pandas ``dtype``s. The provided\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;124;03m            ``dtype`` is used when constructing the series for the column\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;124;03m            specified. Otherwise, the default pandas behavior is used.\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \n\u001b[0;32m   1870\u001b[0m \u001b[38;5;124;03m        progress_bar_type (Optional[str]):\u001b[39;00m\n\u001b[0;32m   1871\u001b[0m \u001b[38;5;124;03m            If set, use the `tqdm <https://tqdm.github.io/>`_ library to\u001b[39;00m\n\u001b[0;32m   1872\u001b[0m \u001b[38;5;124;03m            display a progress bar while the data downloads. Install the\u001b[39;00m\n\u001b[0;32m   1873\u001b[0m \u001b[38;5;124;03m            ``tqdm`` package to use this feature.\u001b[39;00m\n\u001b[0;32m   1874\u001b[0m \n\u001b[0;32m   1875\u001b[0m \u001b[38;5;124;03m            See\u001b[39;00m\n\u001b[0;32m   1876\u001b[0m \u001b[38;5;124;03m            :func:`~google.cloud.bigquery.table.RowIterator.to_dataframe`\u001b[39;00m\n\u001b[0;32m   1877\u001b[0m \u001b[38;5;124;03m            for details.\u001b[39;00m\n\u001b[0;32m   1878\u001b[0m \n\u001b[0;32m   1879\u001b[0m \u001b[38;5;124;03m            .. versionadded:: 1.11.0\u001b[39;00m\n\u001b[0;32m   1880\u001b[0m \u001b[38;5;124;03m        create_bqstorage_client (Optional[bool]):\u001b[39;00m\n\u001b[0;32m   1881\u001b[0m \u001b[38;5;124;03m            If ``True`` (default), create a BigQuery Storage API client\u001b[39;00m\n\u001b[0;32m   1882\u001b[0m \u001b[38;5;124;03m            using the default API settings. The BigQuery Storage API\u001b[39;00m\n\u001b[0;32m   1883\u001b[0m \u001b[38;5;124;03m            is a faster way to fetch rows from BigQuery. See the\u001b[39;00m\n\u001b[0;32m   1884\u001b[0m \u001b[38;5;124;03m            ``bqstorage_client`` parameter for more information.\u001b[39;00m\n\u001b[0;32m   1885\u001b[0m \n\u001b[0;32m   1886\u001b[0m \u001b[38;5;124;03m            This argument does nothing if ``bqstorage_client`` is supplied.\u001b[39;00m\n\u001b[0;32m   1887\u001b[0m \n\u001b[0;32m   1888\u001b[0m \u001b[38;5;124;03m            .. versionadded:: 1.24.0\u001b[39;00m\n\u001b[0;32m   1889\u001b[0m \n\u001b[0;32m   1890\u001b[0m \u001b[38;5;124;03m        max_results (Optional[int]):\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m \u001b[38;5;124;03m            Maximum number of rows to include in the result. No limit by default.\u001b[39;00m\n\u001b[0;32m   1892\u001b[0m \n\u001b[0;32m   1893\u001b[0m \u001b[38;5;124;03m            .. versionadded:: 2.21.0\u001b[39;00m\n\u001b[0;32m   1894\u001b[0m \n\u001b[0;32m   1895\u001b[0m \u001b[38;5;124;03m        geography_as_object (Optional[bool]):\u001b[39;00m\n\u001b[0;32m   1896\u001b[0m \u001b[38;5;124;03m            If ``True``, convert GEOGRAPHY data to :mod:`shapely`\u001b[39;00m\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;124;03m            geometry objects.  If ``False`` (default), don't cast\u001b[39;00m\n\u001b[0;32m   1898\u001b[0m \u001b[38;5;124;03m            geography data to :mod:`shapely` geometry objects.\u001b[39;00m\n\u001b[0;32m   1899\u001b[0m \n\u001b[0;32m   1900\u001b[0m \u001b[38;5;124;03m            .. versionadded:: 2.24.0\u001b[39;00m\n\u001b[0;32m   1901\u001b[0m \n\u001b[0;32m   1902\u001b[0m \u001b[38;5;124;03m        bool_dtype (Optional[pandas.Series.dtype, None]):\u001b[39;00m\n\u001b[0;32m   1903\u001b[0m \u001b[38;5;124;03m            If set, indicate a pandas ExtensionDtype (e.g. ``pandas.BooleanDtype()``)\u001b[39;00m\n\u001b[0;32m   1904\u001b[0m \u001b[38;5;124;03m            to convert BigQuery Boolean type, instead of relying on the default\u001b[39;00m\n\u001b[0;32m   1905\u001b[0m \u001b[38;5;124;03m            ``pandas.BooleanDtype()``. If you explicitly set the value to ``None``,\u001b[39;00m\n\u001b[0;32m   1906\u001b[0m \u001b[38;5;124;03m            then the data type will be ``numpy.dtype(\"bool\")``. BigQuery Boolean\u001b[39;00m\n\u001b[0;32m   1907\u001b[0m \u001b[38;5;124;03m            type can be found at:\u001b[39;00m\n\u001b[0;32m   1908\u001b[0m \u001b[38;5;124;03m            https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#boolean_type\u001b[39;00m\n\u001b[0;32m   1909\u001b[0m \n\u001b[0;32m   1910\u001b[0m \u001b[38;5;124;03m            .. versionadded:: 3.8.0\u001b[39;00m\n\u001b[0;32m   1911\u001b[0m \n\u001b[0;32m   1912\u001b[0m \u001b[38;5;124;03m        int_dtype (Optional[pandas.Series.dtype, None]):\u001b[39;00m\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;124;03m            If set, indicate a pandas ExtensionDtype (e.g. ``pandas.Int64Dtype()``)\u001b[39;00m\n\u001b[0;32m   1914\u001b[0m \u001b[38;5;124;03m            to convert BigQuery Integer types, instead of relying on the default\u001b[39;00m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;124;03m            ``pandas.Int64Dtype()``. If you explicitly set the value to ``None``,\u001b[39;00m\n\u001b[0;32m   1916\u001b[0m \u001b[38;5;124;03m            then the data type will be ``numpy.dtype(\"int64\")``. A list of BigQuery\u001b[39;00m\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;124;03m            Integer types can be found at:\u001b[39;00m\n\u001b[0;32m   1918\u001b[0m \u001b[38;5;124;03m            https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#integer_types\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m \n\u001b[0;32m   1920\u001b[0m \u001b[38;5;124;03m            .. versionadded:: 3.8.0\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \n\u001b[0;32m   1922\u001b[0m \u001b[38;5;124;03m        float_dtype (Optional[pandas.Series.dtype, None]):\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;124;03m            If set, indicate a pandas ExtensionDtype (e.g. ``pandas.Float32Dtype()``)\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;124;03m            to convert BigQuery Float type, instead of relying on the default\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;124;03m            ``numpy.dtype(\"float64\")``. If you explicitly set the value to ``None``,\u001b[39;00m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;124;03m            then the data type will be ``numpy.dtype(\"float64\")``. BigQuery Float\u001b[39;00m\n\u001b[0;32m   1927\u001b[0m \u001b[38;5;124;03m            type can be found at:\u001b[39;00m\n\u001b[0;32m   1928\u001b[0m \u001b[38;5;124;03m            https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#floating_point_types\u001b[39;00m\n\u001b[0;32m   1929\u001b[0m \n\u001b[0;32m   1930\u001b[0m \u001b[38;5;124;03m            .. versionadded:: 3.8.0\u001b[39;00m\n\u001b[0;32m   1931\u001b[0m \n\u001b[0;32m   1932\u001b[0m \u001b[38;5;124;03m        string_dtype (Optional[pandas.Series.dtype, None]):\u001b[39;00m\n\u001b[0;32m   1933\u001b[0m \u001b[38;5;124;03m            If set, indicate a pandas ExtensionDtype (e.g. ``pandas.StringDtype()``) to\u001b[39;00m\n\u001b[0;32m   1934\u001b[0m \u001b[38;5;124;03m            convert BigQuery String type, instead of relying on the default\u001b[39;00m\n\u001b[0;32m   1935\u001b[0m \u001b[38;5;124;03m            ``numpy.dtype(\"object\")``. If you explicitly set the value to ``None``,\u001b[39;00m\n\u001b[0;32m   1936\u001b[0m \u001b[38;5;124;03m            then the data type will be ``numpy.dtype(\"object\")``. BigQuery String\u001b[39;00m\n\u001b[0;32m   1937\u001b[0m \u001b[38;5;124;03m            type can be found at:\u001b[39;00m\n\u001b[0;32m   1938\u001b[0m \u001b[38;5;124;03m            https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#string_type\u001b[39;00m\n\u001b[0;32m   1939\u001b[0m \n\u001b[0;32m   1940\u001b[0m \u001b[38;5;124;03m            .. versionadded:: 3.8.0\u001b[39;00m\n\u001b[0;32m   1941\u001b[0m \n\u001b[0;32m   1942\u001b[0m \u001b[38;5;124;03m        date_dtype (Optional[pandas.Series.dtype, None]):\u001b[39;00m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;124;03m            If set, indicate a pandas ExtensionDtype (e.g.\u001b[39;00m\n\u001b[0;32m   1944\u001b[0m \u001b[38;5;124;03m            ``pandas.ArrowDtype(pyarrow.date32())``) to convert BigQuery Date\u001b[39;00m\n\u001b[0;32m   1945\u001b[0m \u001b[38;5;124;03m            type, instead of relying on the default ``db_dtypes.DateDtype()``.\u001b[39;00m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;124;03m            If you explicitly set the value to ``None``, then the data type will be\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;124;03m            ``numpy.dtype(\"datetime64[ns]\")`` or ``object`` if out of bound. BigQuery\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;124;03m            Date type can be found at:\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;124;03m            https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#date_type\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \n\u001b[0;32m   1951\u001b[0m \u001b[38;5;124;03m            .. versionadded:: 3.10.0\u001b[39;00m\n\u001b[0;32m   1952\u001b[0m \n\u001b[0;32m   1953\u001b[0m \u001b[38;5;124;03m        datetime_dtype (Optional[pandas.Series.dtype, None]):\u001b[39;00m\n\u001b[0;32m   1954\u001b[0m \u001b[38;5;124;03m            If set, indicate a pandas ExtensionDtype (e.g.\u001b[39;00m\n\u001b[0;32m   1955\u001b[0m \u001b[38;5;124;03m            ``pandas.ArrowDtype(pyarrow.timestamp(\"us\"))``) to convert BigQuery Datetime\u001b[39;00m\n\u001b[0;32m   1956\u001b[0m \u001b[38;5;124;03m            type, instead of relying on the default ``numpy.dtype(\"datetime64[ns]``.\u001b[39;00m\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;124;03m            If you explicitly set the value to ``None``, then the data type will be\u001b[39;00m\n\u001b[0;32m   1958\u001b[0m \u001b[38;5;124;03m            ``numpy.dtype(\"datetime64[ns]\")`` or ``object`` if out of bound. BigQuery\u001b[39;00m\n\u001b[0;32m   1959\u001b[0m \u001b[38;5;124;03m            Datetime type can be found at:\u001b[39;00m\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;124;03m            https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#datetime_type\u001b[39;00m\n\u001b[0;32m   1961\u001b[0m \n\u001b[0;32m   1962\u001b[0m \u001b[38;5;124;03m            .. versionadded:: 3.10.0\u001b[39;00m\n\u001b[0;32m   1963\u001b[0m \n\u001b[0;32m   1964\u001b[0m \u001b[38;5;124;03m        time_dtype (Optional[pandas.Series.dtype, None]):\u001b[39;00m\n\u001b[0;32m   1965\u001b[0m \u001b[38;5;124;03m            If set, indicate a pandas ExtensionDtype (e.g.\u001b[39;00m\n\u001b[0;32m   1966\u001b[0m \u001b[38;5;124;03m            ``pandas.ArrowDtype(pyarrow.time64(\"us\"))``) to convert BigQuery Time\u001b[39;00m\n\u001b[0;32m   1967\u001b[0m \u001b[38;5;124;03m            type, instead of relying on the default ``db_dtypes.TimeDtype()``.\u001b[39;00m\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;124;03m            If you explicitly set the value to ``None``, then the data type will be\u001b[39;00m\n\u001b[0;32m   1969\u001b[0m \u001b[38;5;124;03m            ``numpy.dtype(\"object\")``. BigQuery Time type can be found at:\u001b[39;00m\n\u001b[0;32m   1970\u001b[0m \u001b[38;5;124;03m            https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#time_type\u001b[39;00m\n\u001b[0;32m   1971\u001b[0m \n\u001b[0;32m   1972\u001b[0m \u001b[38;5;124;03m            .. versionadded:: 3.10.0\u001b[39;00m\n\u001b[0;32m   1973\u001b[0m \n\u001b[0;32m   1974\u001b[0m \u001b[38;5;124;03m        timestamp_dtype (Optional[pandas.Series.dtype, None]):\u001b[39;00m\n\u001b[0;32m   1975\u001b[0m \u001b[38;5;124;03m            If set, indicate a pandas ExtensionDtype (e.g.\u001b[39;00m\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;124;03m            ``pandas.ArrowDtype(pyarrow.timestamp(\"us\", tz=\"UTC\"))``) to convert BigQuery Timestamp\u001b[39;00m\n\u001b[0;32m   1977\u001b[0m \u001b[38;5;124;03m            type, instead of relying on the default ``numpy.dtype(\"datetime64[ns, UTC]\")``.\u001b[39;00m\n\u001b[0;32m   1978\u001b[0m \u001b[38;5;124;03m            If you explicitly set the value to ``None``, then the data type will be\u001b[39;00m\n\u001b[0;32m   1979\u001b[0m \u001b[38;5;124;03m            ``numpy.dtype(\"datetime64[ns, UTC]\")`` or ``object`` if out of bound. BigQuery\u001b[39;00m\n\u001b[0;32m   1980\u001b[0m \u001b[38;5;124;03m            Datetime type can be found at:\u001b[39;00m\n\u001b[0;32m   1981\u001b[0m \u001b[38;5;124;03m            https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#timestamp_type\u001b[39;00m\n\u001b[0;32m   1982\u001b[0m \n\u001b[0;32m   1983\u001b[0m \u001b[38;5;124;03m            .. versionadded:: 3.10.0\u001b[39;00m\n\u001b[0;32m   1984\u001b[0m \n\u001b[0;32m   1985\u001b[0m \u001b[38;5;124;03m        range_date_dtype (Optional[pandas.Series.dtype, None]):\u001b[39;00m\n\u001b[0;32m   1986\u001b[0m \u001b[38;5;124;03m            If set, indicate a pandas ExtensionDtype, such as:\u001b[39;00m\n\u001b[0;32m   1987\u001b[0m \n\u001b[0;32m   1988\u001b[0m \u001b[38;5;124;03m            .. code-block:: python\u001b[39;00m\n\u001b[0;32m   1989\u001b[0m \n\u001b[0;32m   1990\u001b[0m \u001b[38;5;124;03m                pandas.ArrowDtype(pyarrow.struct(\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;124;03m                    [(\"start\", pyarrow.date32()), (\"end\", pyarrow.date32())]\u001b[39;00m\n\u001b[0;32m   1992\u001b[0m \u001b[38;5;124;03m                ))\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m \n\u001b[0;32m   1994\u001b[0m \u001b[38;5;124;03m            to convert BigQuery RANGE<DATE> type, instead of relying on\u001b[39;00m\n\u001b[0;32m   1995\u001b[0m \u001b[38;5;124;03m            the default ``object``. If you explicitly set the value to\u001b[39;00m\n\u001b[0;32m   1996\u001b[0m \u001b[38;5;124;03m            ``None``, the data type will be ``object``. BigQuery Range type\u001b[39;00m\n\u001b[0;32m   1997\u001b[0m \u001b[38;5;124;03m            can be found at:\u001b[39;00m\n\u001b[0;32m   1998\u001b[0m \u001b[38;5;124;03m            https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#range_type\u001b[39;00m\n\u001b[0;32m   1999\u001b[0m \n\u001b[0;32m   2000\u001b[0m \u001b[38;5;124;03m            .. versionadded:: 3.21.0\u001b[39;00m\n\u001b[0;32m   2001\u001b[0m \n\u001b[0;32m   2002\u001b[0m \u001b[38;5;124;03m        range_datetime_dtype (Optional[pandas.Series.dtype, None]):\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;124;03m            If set, indicate a pandas ExtensionDtype, such as:\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \n\u001b[0;32m   2005\u001b[0m \u001b[38;5;124;03m            .. code-block:: python\u001b[39;00m\n\u001b[0;32m   2006\u001b[0m \n\u001b[0;32m   2007\u001b[0m \u001b[38;5;124;03m                pandas.ArrowDtype(pyarrow.struct(\u001b[39;00m\n\u001b[0;32m   2008\u001b[0m \u001b[38;5;124;03m                    [\u001b[39;00m\n\u001b[0;32m   2009\u001b[0m \u001b[38;5;124;03m                        (\"start\", pyarrow.timestamp(\"us\")),\u001b[39;00m\n\u001b[0;32m   2010\u001b[0m \u001b[38;5;124;03m                        (\"end\", pyarrow.timestamp(\"us\")),\u001b[39;00m\n\u001b[0;32m   2011\u001b[0m \u001b[38;5;124;03m                    ]\u001b[39;00m\n\u001b[0;32m   2012\u001b[0m \u001b[38;5;124;03m                ))\u001b[39;00m\n\u001b[0;32m   2013\u001b[0m \n\u001b[0;32m   2014\u001b[0m \u001b[38;5;124;03m            to convert BigQuery RANGE<DATETIME> type, instead of relying on\u001b[39;00m\n\u001b[0;32m   2015\u001b[0m \u001b[38;5;124;03m            the default ``object``. If you explicitly set the value to\u001b[39;00m\n\u001b[0;32m   2016\u001b[0m \u001b[38;5;124;03m            ``None``, the data type will be ``object``. BigQuery Range type\u001b[39;00m\n\u001b[0;32m   2017\u001b[0m \u001b[38;5;124;03m            can be found at:\u001b[39;00m\n\u001b[0;32m   2018\u001b[0m \u001b[38;5;124;03m            https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#range_type\u001b[39;00m\n\u001b[0;32m   2019\u001b[0m \n\u001b[0;32m   2020\u001b[0m \u001b[38;5;124;03m            .. versionadded:: 3.21.0\u001b[39;00m\n\u001b[0;32m   2021\u001b[0m \n\u001b[0;32m   2022\u001b[0m \u001b[38;5;124;03m        range_timestamp_dtype (Optional[pandas.Series.dtype, None]):\u001b[39;00m\n\u001b[0;32m   2023\u001b[0m \u001b[38;5;124;03m            If set, indicate a pandas ExtensionDtype, such as:\u001b[39;00m\n\u001b[0;32m   2024\u001b[0m \n\u001b[0;32m   2025\u001b[0m \u001b[38;5;124;03m            .. code-block:: python\u001b[39;00m\n\u001b[0;32m   2026\u001b[0m \n\u001b[0;32m   2027\u001b[0m \u001b[38;5;124;03m                pandas.ArrowDtype(pyarrow.struct(\u001b[39;00m\n\u001b[0;32m   2028\u001b[0m \u001b[38;5;124;03m                    [\u001b[39;00m\n\u001b[0;32m   2029\u001b[0m \u001b[38;5;124;03m                        (\"start\", pyarrow.timestamp(\"us\", tz=\"UTC\")),\u001b[39;00m\n\u001b[0;32m   2030\u001b[0m \u001b[38;5;124;03m                        (\"end\", pyarrow.timestamp(\"us\", tz=\"UTC\")),\u001b[39;00m\n\u001b[0;32m   2031\u001b[0m \u001b[38;5;124;03m                    ]\u001b[39;00m\n\u001b[0;32m   2032\u001b[0m \u001b[38;5;124;03m                ))\u001b[39;00m\n\u001b[0;32m   2033\u001b[0m \n\u001b[0;32m   2034\u001b[0m \u001b[38;5;124;03m            to convert BigQuery RANGE<TIMESTAMP> type, instead of relying\u001b[39;00m\n\u001b[0;32m   2035\u001b[0m \u001b[38;5;124;03m            on the default ``object``. If you explicitly set the value to\u001b[39;00m\n\u001b[0;32m   2036\u001b[0m \u001b[38;5;124;03m            ``None``, the data type will be ``object``. BigQuery Range type\u001b[39;00m\n\u001b[0;32m   2037\u001b[0m \u001b[38;5;124;03m            can be found at:\u001b[39;00m\n\u001b[0;32m   2038\u001b[0m \u001b[38;5;124;03m            https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#range_type\u001b[39;00m\n\u001b[0;32m   2039\u001b[0m \n\u001b[0;32m   2040\u001b[0m \u001b[38;5;124;03m            .. versionadded:: 3.21.0\u001b[39;00m\n\u001b[0;32m   2041\u001b[0m \n\u001b[0;32m   2042\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;124;03m        pandas.DataFrame:\u001b[39;00m\n\u001b[0;32m   2044\u001b[0m \u001b[38;5;124;03m            A :class:`~pandas.DataFrame` populated with row data\u001b[39;00m\n\u001b[0;32m   2045\u001b[0m \u001b[38;5;124;03m            and column headers from the query results. The column\u001b[39;00m\n\u001b[0;32m   2046\u001b[0m \u001b[38;5;124;03m            headers are derived from the destination table's\u001b[39;00m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;124;03m            schema.\u001b[39;00m\n\u001b[0;32m   2048\u001b[0m \n\u001b[0;32m   2049\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[0;32m   2050\u001b[0m \u001b[38;5;124;03m        ValueError:\u001b[39;00m\n\u001b[0;32m   2051\u001b[0m \u001b[38;5;124;03m            If the :mod:`pandas` library cannot be imported, or\u001b[39;00m\n\u001b[1;32m-> 2052\u001b[0m \u001b[38;5;124;03m            the :mod:`google.cloud.bigquery_storage_v1` module is\u001b[39;00m\n\u001b[0;32m   2053\u001b[0m \u001b[38;5;124;03m            required but cannot be imported.  Also if\u001b[39;00m\n\u001b[0;32m   2054\u001b[0m \u001b[38;5;124;03m            `geography_as_object` is `True`, but the\u001b[39;00m\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;124;03m            :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[0;32m   2056\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2057\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m   2058\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m query_result\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[0;32m   2059\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39mbqstorage_client,\n\u001b[0;32m   2060\u001b[0m         dtypes\u001b[38;5;241m=\u001b[39mdtypes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2074\u001b[0m         range_timestamp_dtype\u001b[38;5;241m=\u001b[39mrange_timestamp_dtype,\n\u001b[0;32m   2075\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\cloud\\bigquery\\_tqdm_helpers.py:107\u001b[0m, in \u001b[0;36mwait_for_query\u001b[1;34m(query_job, progress_bar_type, max_results)\u001b[0m\n\u001b[0;32m    103\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m get_progress_bar(\n\u001b[0;32m    104\u001b[0m     progress_bar_type, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery is running\u001b[39m\u001b[38;5;124m\"\u001b[39m, default_total, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m )\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m progress_bar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\cloud\\bigquery\\job\\query.py:1676\u001b[0m, in \u001b[0;36mresult\u001b[1;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[0;32m   1667\u001b[0m     remaining_timeout \u001b[38;5;241m=\u001b[39m timeout\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1669\u001b[0m     \u001b[38;5;66;03m# Note: we may need to handle _DEFAULT_VALUE as a separate\u001b[39;00m\n\u001b[0;32m   1670\u001b[0m     \u001b[38;5;66;03m# case someday, but even then the best we can do for queries\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1674\u001b[0m     \u001b[38;5;66;03m# The timeout for a multi-statement query is 24+ hours. See:\u001b[39;00m\n\u001b[0;32m   1675\u001b[0m     \u001b[38;5;66;03m# https://cloud.google.com/bigquery/quotas#multi_statement_query_limits\u001b[39;00m\n\u001b[1;32m-> 1676\u001b[0m     remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;66;03m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[39;00m\n\u001b[0;32m   1680\u001b[0m     \u001b[38;5;66;03m# long-running API, don't delay the next request at all.\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_job_done():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\google\\cloud\\bigquery\\job\\query.py:1625\u001b[0m, in \u001b[0;36mis_job_done\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1604\u001b[0m if self.done(retry=retry, **done_kwargs):\n\u001b[0;32m   1605\u001b[0m     # If it's already failed, we might as well stop.\n\u001b[0;32m   1606\u001b[0m     job_failed_exception = self.exception()\n\u001b[0;32m   1607\u001b[0m     if job_failed_exception is not None:\n\u001b[0;32m   1608\u001b[0m         # Only try to restart the query job if the job failed for\n\u001b[0;32m   1609\u001b[0m         # a retriable reason. For example, don't restart the query\n\u001b[0;32m   1610\u001b[0m         # if the call to reload the job metadata within self.done()\n\u001b[0;32m   1611\u001b[0m         # timed out.\n\u001b[0;32m   1612\u001b[0m         #\n\u001b[0;32m   1613\u001b[0m         # The `restart_query_job` must only be called after a\n\u001b[0;32m   1614\u001b[0m         # successful call to the `jobs.get` REST API and we\n\u001b[0;32m   1615\u001b[0m         # determine that the job has failed.\n\u001b[0;32m   1616\u001b[0m         #\n\u001b[0;32m   1617\u001b[0m         # The `jobs.get` REST API\n\u001b[0;32m   1618\u001b[0m         # (https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get)\n\u001b[0;32m   1619\u001b[0m         #  is called via `self.done()` which calls\n\u001b[0;32m   1620\u001b[0m         # `self.reload()`.\n\u001b[0;32m   1621\u001b[0m         #\n\u001b[0;32m   1622\u001b[0m         # To determine if the job failed, the `self.exception()`\n\u001b[0;32m   1623\u001b[0m         # is set from `self.reload()` via\n\u001b[0;32m   1624\u001b[0m         # `self._set_properties()`, which translates the\n\u001b[1;32m-> 1625\u001b[0m         # `Job.status.errorResult` field\n\u001b[0;32m   1626\u001b[0m         # (https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatus.FIELDS.error_result)\n\u001b[0;32m   1627\u001b[0m         # into an exception that can be processed by the\n\u001b[0;32m   1628\u001b[0m         # `job_retry` predicate.\n\u001b[0;32m   1629\u001b[0m         restart_query_job = True\n\u001b[0;32m   1630\u001b[0m         raise job_failed_exception\n",
      "\u001b[1;31mNotFound\u001b[0m: 404 Not found: Table umt-msba:wedge_project_ochoa.transactions was not found in location US; reason: notFound, message: Not found: Table umt-msba:wedge_project_ochoa.transactions was not found in location US\n\nLocation: US\nJob ID: 4955f81d-b682-4711-a544-aba1f743db48\n"
     ]
    }
   ],
   "source": [
    "## Task 2\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set up BigQuery authentication\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'C:\\Users\\jochoa\\Documents\\GitHub\\wedge_project\\service_account_key.json'\n",
    "\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Get owner records\n",
    "def get_owner_records():\n",
    "    query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM `umt-msba.wedge_project_ochoa.transactions`\n",
    "    WHERE card_no != 3\n",
    "    \"\"\"\n",
    "    results = client.query(query).to_dataframe() \n",
    "    return results\n",
    "\n",
    "# Sample the owners\n",
    "def sample_owners(owner_df, sample_size=250):\n",
    "    sampled_owners = owner_df.sample(n=sample_size, random_state=42)\n",
    "    return sampled_owners\n",
    "\n",
    "# Extract all records for the sampled owners\n",
    "def extract_records_for_sampled_owners(sampled_owners):\n",
    "    owner_card_numbers = sampled_owners['card_no'].tolist()\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT * \n",
    "    FROM `umt-msba.wedge_project_ochoa.transactions`\n",
    "    WHERE card_no IN ({','.join(map(str, owner_card_numbers))})\n",
    "    \"\"\"\n",
    "    records = client.query(query).to_dataframe()\n",
    "    return records\n",
    "\n",
    "# Write the records to a local text file\n",
    "def write_records_to_file(records, file_name=\"sampled_owners_records.csv\"):\n",
    "    records.to_csv(file_name, index=False)\n",
    "    print(f\"Records written to {file_name}\")\n",
    "\n",
    "# Upload to BigQuery\n",
    "def upload_to_bigquery(df, table_name):\n",
    "    table_id = f\"umt-msba.wedge_project_ochoa.{table_name}\"\n",
    "    \n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "        autodetect=True\n",
    "    )\n",
    "    load_job = client.load_table_from_dataframe(df, table_id, job_config=job_config)\n",
    "    load_job.result()  \n",
    "    print(f\"Uploaded {len(df)} rows to {table_id}\")\n",
    "\n",
    "# Main workflow\n",
    "if __name__ == \"__main__\":\n",
    "    owners = get_owner_records() \n",
    "    sampled_owners = sample_owners(owners)  \n",
    "    sampled_records = extract_records_for_sampled_owners(sampled_owners) \n",
    "    \n",
    "    write_records_to_file(sampled_records) \n",
    "    \n",
    "    # Upload the sample to BigQuery\n",
    "    upload_to_bigquery(sampled_records, \"sampled_owners\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
